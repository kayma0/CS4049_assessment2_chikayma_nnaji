{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f3af0f9",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning and Data Mining (CS4049)                                                      \n",
    "## Assessment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7c7f15",
   "metadata": {},
   "source": [
    "### 1. Random Sampling.\n",
    "Instructions: Use a random sample of 10K instances drawn from the ~61K instances in the secondary mushroom data, and explain the random sampling code cell(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a535c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 21)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports pandas so we can read and work with the dataset\n",
    "import pandas as pd \n",
    "\n",
    "#reads the mushroom data file, and also tells pandas that the data is seperated by semilcolons\n",
    "df = pd.read_csv(\"MushroomDataset/secondary_data.csv\", sep=\";\")\n",
    "\n",
    "# df.head()\n",
    "# df.shape\n",
    "\n",
    "#pick 10k random rows from the whole dataset\n",
    "df_sample = df.sample(n=10000, random_state= 42)\n",
    "\n",
    "#shows how many rows and columns the sample has \n",
    "df_sample.shape\n",
    "\n",
    "# df_sample.head(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d84377",
   "metadata": {},
   "source": [
    "#### Explanation.\n",
    "\n",
    "The original mushroom dataset (secondary data file) has around 61k rows of data. Working with the full dataset can take more time and use way more computer power when analysing or training models. To make the process faster and easier to manage, based on the instructions, I used the sample() funtion in pandas to randomly select 10k rows from the dataset.\n",
    "\n",
    "This random sample still represents the overall data well because the rows used are chosen randomly. I also included 'random_state=42' which makes sure the same 10k rows are picked everytime I run the notebook, just to ensure consistency, and make sure my results stay the same.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
